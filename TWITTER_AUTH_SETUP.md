# ğŸ” Setting Up Real Twitter Data (Twikit Authentication)

## Current Status
âœ… **Twikit library installed**  
âš ï¸ **Sample data mode active** (authentication not configured)

## Why Sample Data?
Twitter/X requires authentication to scrape tweets. Without credentials, we use AI-generated sample tweets that are topic-specific and demonstrate the full functionality of the app.

---

## ğŸš€ How to Get Real Twitter Data

### Prerequisites
- A Twitter/X account
- Python 3.13 with twikit installed (âœ… Already done!)

### Step 1: Create Twitter Account Credentials

You need a Twitter/X account. The free account works fine for basic scraping.

### Step 2: Set Up Environment Variables

Create a `.env` file in the `backend/` directory:

```env
TWITTER_USERNAME=your_twitter_username
TWITTER_EMAIL=your_twitter_email@example.com
TWITTER_PASSWORD=your_twitter_password
```

### Step 3: Update `scrape_tweets.py`

Replace the `scrape_with_twikit` function with this:

```python
import asyncio
from twikit import Client
import os
from dotenv import load_dotenv

load_dotenv()

async def scrape_with_twikit(query, max_tweets=1000):
    """
    Scrape tweets using Twikit with authentication
    """
    client = Client('en-US')
    
    # Load credentials from environment
    username = os.getenv('TWITTER_USERNAME')
    email = os.getenv('TWITTER_EMAIL')
    password = os.getenv('TWITTER_PASSWORD')
    
    if not all([username, email, password]):
        print("âš  Twitter credentials not found in .env file")
        print("Using sample data instead")
        return generate_sample_tweets(query, max_tweets)
    
    try:
        # Login
        print("ğŸ” Logging into Twitter...")
        await client.login(
            auth_info_1=username,
            auth_info_2=email,
            password=password
        )
        
        # Search tweets
        print(f"ğŸ” Searching for: {query}")
        tweets_list = []
        
        tweets = await client.search_tweet(query, 'Latest')
        
        for i, tweet in enumerate(tweets):
            if i >= max_tweets:
                break
                
            tweets_list.append({
                'date': tweet.created_at,
                'id': tweet.id,
                'content': tweet.text,
                'username': tweet.user.screen_name,
                'like_count': tweet.favorite_count,
                'retweet_count': tweet.retweet_count,
                'reply_count': tweet.reply_count,
                'language': tweet.lang,
                'source': 'Twitter',
                'url': f'https://twitter.com/{tweet.user.screen_name}/status/{tweet.id}'
            })
            
            if (i + 1) % 100 == 0:
                print(f"Scraped {i + 1} tweets...")
        
        print(f"\nâœ“ Successfully scraped {len(tweets_list)} real tweets!")
        return pd.DataFrame(tweets_list)
        
    except Exception as e:
        print(f"âŒ Error scraping with Twikit: {e}")
        print("Falling back to sample data")
        return generate_sample_tweets(query, max_tweets)


def scrape_tweets(query, max_tweets=1000, since_date=None, until_date=None):
    """
    Scrape tweets using twikit or sample data
    """
    if SCRAPER_TYPE == 'twikit':
        # Run async function
        try:
            return asyncio.run(scrape_with_twikit(query, max_tweets))
        except Exception as e:
            print(f"Error: {e}")
            return generate_sample_tweets(query, max_tweets)
    
    return generate_sample_tweets(query, max_tweets)
```

### Step 4: Install python-dotenv

```bash
cd backend
pip install python-dotenv
```

### Step 5: Restart Backend

```bash
cd backend
python app.py
```

---

## ğŸ¯ Alternative: Twitter API v2

If you prefer using official Twitter API:

### Pros:
- âœ… Official and stable
- âœ… Better rate limits with paid plans
- âœ… More reliable

### Cons:
- âŒ Requires Twitter Developer account
- âŒ Free tier is very limited (10,000 tweets/month)
- âŒ Approval process needed

### Setup:
1. Go to https://developer.twitter.com
2. Create a developer account
3. Create a new app
4. Get API keys and tokens
5. Use `tweepy` library instead of twikit

---

## ğŸ“Š Current Sample Data Features

While using sample data, you still get:
- âœ… **Topic-specific tweets** (AI generates relevant content)
- âœ… **Realistic sentiment distribution**
- âœ… **Proper metadata** (likes, retweets, dates)
- âœ… **All analysis features** work identically
- âœ… **Full UI/UX demonstration**

### Sample Data Templates:
- **10 positive templates** per topic
- **10 negative templates** per topic  
- **10 neutral templates** per topic
- **All dynamically include the search topic**

---

## ğŸ”’ Security Notes

**NEVER commit your .env file to Git!**

Add to `.gitignore`:
```
.env
cookies.json
*.log
```

The `.env` file contains sensitive credentials.

---

## ğŸ’¡ Recommendations

For this **internship/learning project**, I recommend:

1. **Keep using sample data** - It's perfect for demonstration
2. **Add the disclaimer banner** - So viewers know it's demo mode
3. **Focus on the ML/Analysis** - The sentiment analysis is the key feature
4. **Later**: Set up real data if you deploy this for production use

### Why Sample Data is OK for Learning:
- âœ… No API rate limits
- âœ… No authentication hassles  
- âœ… Consistent results for testing
- âœ… All features work identically
- âœ… Shows your technical skills regardless

---

## ğŸš€ Quick Setup for Real Data (Summary)

```bash
# 1. Install python-dotenv
pip install python-dotenv

# 2. Create .env in backend/
echo "TWITTER_USERNAME=your_username" > backend/.env
echo "TWITTER_EMAIL=your_email@example.com" >> backend/.env
echo "TWITTER_PASSWORD=your_password" >> backend/.env

# 3. Update scrape_tweets.py (copy code from above)

# 4. Restart backend
python backend/app.py
```

---

## âœ… What's Already Working

Your app is **production-ready** with sample data:
- âœ¨ Modern UI with animations
- ğŸ“Š Real sentiment analysis (VADER)
- ğŸ“ˆ Beautiful visualizations
- ğŸ’¾ Data export functionality
- ğŸ” Search and filter features
- ğŸ“± Fully responsive design

**The only difference with real data would be the tweet content source!**

---

Need help setting up authentication? Let me know! ğŸš€
